+++ 
draft = false
date = 2025-08-15T10:00:00+09:00
title = "プロンプトエンジニアリング学習 #1: 5つの原則と実践テクニック"
description = "『生成AIのプロンプトエンジニアリング』書籍から学んだ5つの原則と実践的なテクニックを詳しく解説。CoT推論、メタプロンプティング、AIエージェントまで網羅。"
slug = "prompt-engineering-learning-01-overview"
authors = ["0xchoux1"]
tags = ["プロンプトエンジニアリング", "LLM", "AI", "学習記録", "ChatGPT", "Claude", "Gemini", "CoT推論", "メタプロンプティング", "AIエージェント", "LangChain"]
categories = ["AI", "学習"]
externalLink = ""
series = ["プロンプトエンジニアリング学習"]
+++

## この記事のゴール
- プロンプトエンジニアリング学習の全体像と学習計画を明確にする
- 書籍の内容を実践的に活用するための学習アプローチを整理する
- 読者が一緒に学習できる環境を構築する

## 学習対象書籍
**『生成AIのプロンプトエンジニアリング ― 信頼できる生成AIの出力を得るための普遍的な入力の原則』**
- 著者: James Phoenix（ジェームス・フェニックス）、Mike Taylor（マイク・テイラー）
- 監訳者: 田村 広平（たむら こうへい）、大野 真一朗（おおの しんいちろう）
- 訳者: 砂長谷 健（すなはせ たける）、土井 健（どい けん）、大貫 峻平（おおぬき しゅんぺい）、石山 将成（いしやま まさなり）
- 出版社: 株式会社オライリー・ジャパン
- 発売元: 株式会社オーム社
- 発行年: 2025年7月
- ISBN: 978-4-8144-0124-6

## プロンプトエンジニアリングの基礎
### プロンプトとは
プロンプト（Prompt）とは、ChatGPTやMidjourneyのような生成AIと対話する際に与える入力のことです。通常はテキストで、AIが何を生成すべきかを指示する「命令書」のような役割を果たします。

### プロンプトエンジニアリングとは
プロンプトエンジニアリング（Prompt Engineering）とは、有用な、あるいは望ましい結果を確実に生み出すプロンプトを発見する過程のことです。単にプロンプトを書くだけでなく、効果的なプロンプトを体系的に設計・最適化する技術分野です。

### なぜプロンプトエンジニアリングを学ぶのか
#### 背景と必要性
- LLMの実用化が進み、プロンプト設計の重要性が高まっている
- 適切なプロンプト設計により、AIの出力品質と信頼性が大幅に向上する
- エンジニアとして、AIシステムの設計・運用に必須のスキル

### 期待される効果
- AIとの効果的な対話技術の習得
- ビジネスプロセスの自動化・効率化
- ユーザー体験の向上とコスト最適化

## 学習計画とロードマップ
### Phase 1: 基礎概念の理解
- プロンプトエンジニアリングの基本原則
- 主要なプロンプトパターンとテクニック
- プロンプト設計のベストプラクティス

## プロンプト設計の重要な問題点（書籍から学んだこと）
### 明らかに修正した方がよい問題

#### 1. 曖昧な方向性
- 生成AIに対して、どのような文体の名前を求めているのか、あるいはどのような特徴が必要なのか、といった要点を伝えていない
- 単語でいいのか、複合語がいいのか、造語でもいいのか、それとも既存の語彙であることが重要なのかが不明確
- 優れた製品名の命名で有名な誰かを、生成AIに再現してほしいのかが不明

#### 2. 形式の定まっていない出力
- 返される名前の数が定まっていない
- たまに番号付きのリストが返ってきたり、冒頭にテキストが含まれたりして、プログラムで解析しにくい
- 一貫性のない出力形式

#### 3. 例の不足
- 良い名前がどのようなものか、生成AIに一切の例を示していない
- インターネット全体の平均的な結果が返されるが、それが望ましいものとは限らない
- 人気のある名前の例や業界で一般的な名前、好みの名前を生成AIに示すべき

#### 4. 限定的な評価
- 良い名前と悪い名前を定義するための一貫した方法がない
- 大量の名前を効率よく評価する方法がない
- 各応答を人の目で評価する必要がある
- 評価システムや測定手段の導入が必要

#### 5. 未分割のタスク
- 1つのプロンプトで多くのことを要求している
- 製品名を付けるには多くの要素が関わるが、重要なタスクをたった一言で生成AIに任せている
- 特定のタスクに特化させることもできず、タスクの処理方法を把握することもできない

## プロンプトの5つの原則（問題点の解決策）

### 1. 方向性を示す
- 望ましいスタイル（テキスト生成の場合は文体、画像生成の場合は画風、など）を詳細に説明する
- 関連する人物を引き合いに出す
- **解決する問題**: 曖昧な方向性

### 2. 出力形式を指定する
- 守るべきルールと応答に必要な構造を定義する
- 一貫性のある出力形式を保証する
- **解決する問題**: 形式の定まっていない出力

### 3. 例を示す
- 求める応答の例をプロンプトに含める
- 具体的な参考例で期待値を明確化する
- **解決する問題**: 例の不足

### 4. 品質を評価する
- 誤りを特定し、応答を評価し、性能に影響を与える要素をテストする
- 評価システムや測定手段を導入する
- **解決する問題**: 限定的な評価

### 5. タスクを分割する
- 複雑な目標のために、タスクを複数のステップに分割し、連鎖させる
- 特定のタスクに特化させ、処理方法を明確化する
- **解決する問題**: 未分割のタスク

## 実践例：製品名ジェネレーターの改善

### 問題の具体例
単純なテキストのプロンプトの問題の1つは、どのようなタイプの製品名を望んでいるかを生成AIに伝えていなかったことです。製品の命名はある程度、主観的なものであり、生成AIにどのような名前が好ましいのかを伝えなければ、適切な名前を生成する確率は低くなります。

### 解決策：ロールプロンプティング
最適化された製品名ジェネレーターのプロンプトでは、**ロールプレイング（Role-playing：現実を想定して役割を演じる方法）**をプロンプトの作成に応用する**ロールプロンプティング**を使用して方向性を示しました。つまり、製品の象徴的な命名で有名なスティーブ・ジョブズのスタイルを再現しました。

### ロールプロンプティングの効果
- **方向性の明確化**: 特定の人物のスタイルを指定することで、望ましい方向性を示す
- **一貫性の向上**: 同じ人物のスタイルを再現することで、一貫した結果を得られる
- **主観性の克服**: 抽象的な「良い名前」ではなく、具体的なスタイルを指定

### もう一つの手法：プリウォーミング（Prewarming）
意図した製品名を得るために生成AIに従わせたいルールやベストプラクティスをプロンプトに含めておくことで、意図した方向に生成AIを導くことができます。この手法は、**プリウォーミング（Prewarming）**または**内部検索（Internal Retrieval）**と呼ばれることがあり、単純ですが効果的です（Liu et al., 2021）。

#### プリウォーミングの仕組み
会話を始める際に、ユーザーは生成AIにベストプラクティスについて助言を求め、その後、生成AIは自分自身の助言に従った回答を行うように求めます。実際には、生成AIが自身の方向性を自分で決定するように仕向けているのです。

#### プリウォーミングの利点
- **自己制御**: AIが自分でベストプラクティスを決定し、それに従う
- **一貫性**: 同じAIが自分で決めたルールに従うため、一貫した結果
- **効果性**: 単純だが効果的な手法

### 外部リソース活用戦略：コンテキスト挿入
私たちの経験上で、もう1つの有益な戦略は、達成したいタスクに関する最も良い助言をプロンプトにコンテキストとして挿入することです。例えば、Brandwatchの「How to Name a Product: 5 Golden Rules we Follow」や他の信頼できる外部リソースを見つけて、それをプロンプトにコンテキストとして挿入することができます。

#### コンテキスト挿入の効果
- **品質向上**: 信頼できる外部リソースの知見を活用
- **専門性**: 業界のベストプラクティスを反映
- **一貫性**: 確立されたルールに基づく結果

#### トレードオフの考慮
これによりプロンプトの長さが大幅に増加し、開発者としてAPIを利用する場合は費用もかかりますが、応答の質が向上するのであれば、そのトレードオフには価値があるかもしれません。

#### 実践的なアプローチ
- **信頼できるソース**: 業界で認められたリソースを選択
- **コスト管理**: プロンプト長とAPIコストのバランス
- **効果測定**: 品質向上とコスト増加の比較検討

## 第2の原則「出力形式を指定する」の詳細

### 万能翻訳機としての生成AI
生成AIはいわば**万能翻訳機（Universal Translator）**です。これは、フランス語から英語、ウルドゥー語からクリンゴン語への翻訳だけでなく、**JSONからYAML、自然言語からPythonコードへの変換**も可能であることを意味します。

### 出力形式指定の重要性
生成AIはほぼどのような形式でも応答を返すことができるため、プロンプトエンジニアリングにおいて、**応答の形式を指定する方法を習得することは重要**です。

### 具体的な変換例
- **言語間翻訳**: フランス語 → 英語、ウルドゥー語 → クリンゴン語
- **データ形式変換**: JSON → YAML、XML → JSON
- **コード生成**: 自然言語 → Pythonコード、自然言語 → SQLクエリ
- **構造化データ**: テキスト → 表形式、テキスト → リスト形式

## 第3の原則「例を示す」の詳細

### 例を示さないことの問題
製品名ジェネレーターの最初のプロンプトでは、生成AIに良い名前の例を全く示していませんでした。そのため、応答はインターネット上でよく見るような平凡な名前に近いものになってしまいましたが、もっと良い結果を得ることができます。

### ショット学習の概念
研究者は、例を示さないプロンプトを**ゼロショット（Zero-shot）**と呼びます。生成AIがゼロショットでタスクを遂行できる場合、それは強力なモデルの証拠で、常に思いがけない喜びとなります。

#### ショット学習の種類
- **ゼロショット（Zero-shot）**: 例を全く示さない
- **ワンショット（One-shot）**: たった1つの例を示す
- **フューショット（Few-shot）**: 複数の例を示す

### 例を示すことの効果
たった1つの例を示す（ワンショット）だけでも大いに役立ちますし、複数の例を示して（フューショット）モデルの性能をテストすることが研究者の間では一般的です。

### 研究による裏付け
著名なGPT-3の論文「Language Models are Few-Shot Learners」はそのような研究の一例であり、プロンプトに1つの例を追加することで、いくつかのタスクでの精度が**10％から50％近く向上**することが報告されています。

#### 実践的な示唆
- **最小限の例**: 1つの例でも大幅な性能向上が期待できる
- **段階的改善**: ゼロショット → ワンショット → フューショットの順で改善
- **研究ベース**: 学術的な裏付けのある手法

## 第4の原則「品質を評価する」の詳細

### 基本的な評価方法：ブラインドプロンプティング
応答の品質を評価する方法として、まず思い浮かぶのは**ブラインドプロンプティング（Blind Prompting）**のような単純な方法です。これは、プロンプトの実行と応答の確認を繰り返して試行錯誤することです。

#### ブラインドプロンプティングの適用場面
- **一時的な使用**: プロンプトが単一のタスクのために使用され、めったに再利用されない場合
- **問題なし**: 単発のタスクには適している

### 本格的な評価の必要性
同じプロンプトを何度も再利用したり、プロンプトに依存する本番アプリケーションを構築したりする場合は、結果を測定することについてもっと厳密になる必要があります。

### 性能評価の方法
性能を評価する方法はいくつかあり、達成したいタスクに大きく依存します。新しい生成AIのモデルがリリースされたとき、そのモデルが性能評価ベンチマークでどれだけ性能を発揮したかに焦点が当てられます。

#### 性能評価ベンチマークの特徴
- **標準化された質問集**: 特定のタスクに対して事前定義された質問
- **事前定義された回答**: 評価基準が明確
- **比較可能性**: 複数のモデルの性能を比較できる

### モデル間の性能差
同じ種類のタスクであっても、異なるモデルは異なる性能を示すため、以前にうまくいったプロンプトが新しいモデルでもうまくいく保証はありません。

### 評価フレームワーク：OpenAI Evals
OpenAIは、LLMの性能評価ベンチマークのフレームワークである**OpenAI Evals**をオープンソース化しており、評価テンプレートの追加に貢献することを推奨しています。

#### 実践的な示唆
- **段階的評価**: ブラインドプロンプティング → ベンチマーク評価 → フレームワーク活用
- **継続的改善**: モデル更新時の再評価の重要性
- **オープンソース活用**: OpenAI Evalsなどの既存フレームワークの活用

## 第5の原則「タスクを分割する」の詳細

### 複雑なプロンプトの問題
プロンプトを構築していくうちに、1回の生成AIの呼び出しで多くのことを要求してしまうことが少なからずあります。プロンプトが長く複雑になると、応答が1つに定まりづらくなったり、ハルシネーションや異常値が発生する可能性が高まります。

### タスク分割の必要性
タスクに対して信頼できるプロンプトに到達できたとしても、そのタスクはおそらく、ある複雑なタスクを遂行するために必要な、相互に関連した多くのタスクの一部に過ぎません。そのため、他の多くのタスクを生成AIで実行できるかどうか、またそれらをどのように連携させるかを探り始めるのは自然なことです。

### タスク分割の原則
プロンプトエンジニアリングの5つの原則の1つは、タスクを分割して問題をその構成要素に分解することです。これにより、個々の問題をより簡単に解決し、それらの結果を再統合することができます。

#### タスク分割の利点
- **複雑なタスクの達成**: より複雑なタスクを達成できる
- **失敗箇所の特定**: 連鎖した呼び出しのどの部分が失敗しているかをより明確に把握
- **個別解決**: 個々の問題をより簡単に解決
- **結果の再統合**: 分割した結果を再統合

### 製品命名におけるタスク分割の例
製品の命名には多くの要素が関わっており、重要なタスクを生成AIに何も考えずに任せると、これらの要素の重要性をどのように重み付けしているのかについての見通しが立たなくなります。

#### 現在の問題点
ここまで見てきた製品名ジェネレーターの出力結果から、名前のリストは常に取得できているものの、すべての名前が同等な重要度であり、名前の決定を助けるために必要な背景情報が出力されていないことがわかります。

### 自己評価の活用
幸いなことに、生成AIは自己評価が可能で、タスクに第2のステップを追加すれば、望ましくない出力を自動的にチェックすることができます。

#### 実践的な示唆
- **段階的処理**: 複雑なタスクを複数のステップに分割
- **連鎖呼び出し**: 複数の生成AI呼び出しを連携
- **自己評価**: AIの自己評価能力を活用した品質チェック
- **背景情報**: 出力結果の背景情報や重要度の明示

## 高度なテクニック：CoT推論とメタプロンプティング

### CoT推論（Chain-of-Thought Reasoning）
このようにLLMが段階的に考えることを指示する手法は、**CoT推論（Chain-of-Thought Reasoning：思考の連鎖による推論）**と呼ばれています。OpenAIではこのようなプロンプティングの手法を「モデルに考える時間を与える」と呼んでおり、これはプロンプトエンジニアリングの重要な原則とされています。

#### CoT推論の効果
実際、CoT推論により、LLMは自らの思考過程を順番に説明するようになり、まるでタスクを分割したような結果が得られます（ここでは1つの応答内で製品名に点数を付けることと、点数の理由を説明することを実施しました）。

### メタプロンプティング（Meta Prompting）
製品のアイデアに基づいて製品名を自動生成したら、以下のようにChatGPTを再度呼び出して各製品を説明させ、今度はその説明をMidjourneyに入力して各製品の画像を生成することができます。

#### メタプロンプティングの定義
**生成AIを使って生成AIのためのプロンプトを生成すること**はメタプロンプティング（Meta Prompting）と呼ばれ、効果的です。なぜならLLMは人間レベルのプロンプトエンジニアだからです（Zhou, 2022）。

#### メタプロンプティングの実用例
1. **ChatGPT**: 製品名の生成
2. **ChatGPT**: 各製品の説明生成
3. **Midjourney**: 説明を基にした画像生成

#### 実践的な示唆
- **思考の可視化**: CoT推論による思考過程の明示化
- **段階的処理**: 1つの応答内での複数タスクの実行
- **AI連携**: 複数の生成AIの連携活用
- **自動化**: プロンプト生成の自動化

## 実用的な実装：プロンプトチェーンとAIエージェント

### 複数生成AIモデルの連携
生成AIを専門的に扱う際には、より複雑な目標を達成するために、単一の生成AIモデルへの複数のプロンプトの使用だけでなく、**複数の生成AIモデルの連携**も行うのが一般的です。

#### 動的なプロンプト構築
単一のプロンプトを使用するアプリケーションでも、外部のデータベースからの問い合わせや他の生成AIへの呼び出しに基づいて動的に構築されることがよくあります。

### LangChainライブラリーの活用
**LangChain**というライブラリーは、複数のプロンプトのテンプレートやクエリーを連携させる機能を提供しており、その過程をより観察可能で構造化されたものにすることができます。

#### 基本的な例：段階的要約
基本的な例として、コンテキストウィンドウに収まりきらない大きなテキストを複数のチャンクに分割し、それぞれを要約してから最終的に要約をまとめるという**段階的要約**があります。

### プロンプトチェーンの実用性
初期の生成AI製品の開発者と話すと、最終的な出力結果でより良い結果を達成するために、複数のプロンプトを連携させる**プロンプトチェーン（Prompt Chain）**を行っていることがわかります。

### AIエージェントへの応用
プロンプトチェーンは、**AIエージェント**（ユーザーとAIを仲介し、AIを利用してユーザーの目的を達成するプログラム）への応用にも使われています。

#### 自律エージェントの例
**BabyAGI、AgentGPT、Microsoft AutoGen**などのAIエージェントのオープンソースソフトウェア（OSS）は、計画、観察、行動、そして行動の結果を評価するために、複数の生成AIモデルと連携できるように実装されています。

#### 自律エージェントの特徴
これらのAIエージェントは自ら判断して行動するため、**自律エージェント**と呼ばれます。

### 自律エージェントの現状と展望
自律エージェントの実践は、本書の執筆時点でまだ初期段階であり、問題も発生しやすいですが、このアプローチが複雑なタスクを達成するのに有用であることを示す兆しもあり、生成AIシステムの進化の次の段階の一角になる可能性も高いです。

#### 実践的な示唆
- **段階的処理**: 大きなタスクの分割と段階的要約
- **ライブラリー活用**: LangChainなどの既存ツールの活用
- **AI連携**: 複数モデルの連携による複雑タスクの達成
- **将来性**: 自律エージェントによる次世代AIシステム

### Phase 2: 実践的なテクニック
- 具体的なプロンプト例とその効果
- エラー処理とデバッグ手法
- パフォーマンス測定と最適化

### Phase 3: 応用と実装
- 実際のシステムへの組み込み
- セキュリティとガードレール
- 運用とメンテナンス

## 学習方法とアプローチ
### 理論学習
- 書籍の各章を順次読み進める
- 重要な概念の整理と理解
- 実例の分析と考察

### 実践演習
- 各テクニックの実際の試行
- 異なるLLMでの動作確認
- 独自のプロンプトパターンの開発

### 記録と振り返り
- 学習内容のブログ記事化
- 実践結果の記録
- 改善点と次のステップの整理

## 使用するツールと環境
### LLMプラットフォーム
- OpenAI ChatGPT (GPT-4)
- Anthropic Claude
- Google Gemini
- その他オープンソースLLM

### 開発・テスト環境
- Python + Jupyter Notebook
- LangChain / LlamaIndex
- プロンプト管理ツール
- 評価・テストフレームワーク

## 学習の進め方
### 週次学習サイクル
1. **理論学習** (2-3時間): 書籍の該当章を読む
2. **実践演習** (3-4時間): 学んだテクニックを試す
3. **記録・整理** (1-2時間): 学習内容をブログにまとめる
4. **振り返り** (30分): 学習効果と次のステップを確認

### 成果物
- 各章の学習記録ブログ記事
- 実践例とサンプルコード
- 学習の進捗と成果の可視化

## 次回以降の予定
1. **第2回**: プロンプトエンジニアリングの基本原則
2. **第3回**: 主要なプロンプトパターン
3. **第4回**: 実践的なテクニックと応用
4. **第5回**: システム設計への組み込み
5. **第6回**: 学習の総括と今後の展望

## 読者へのお願い
- コメントやフィードバックをお気軽にお寄せください
- 一緒に学習を進めたい方は、同じ書籍を手に取ってください
- 実践例や改善案があれば、ぜひ共有してください

## メモ
- この記事はドラフトです。学習が進むにつれて内容を更新していきます。
- 実際の学習内容や実践例を追加していく予定です。
- 読者の皆さんと一緒に成長できる学習コミュニティを作っていきたいと思います。
